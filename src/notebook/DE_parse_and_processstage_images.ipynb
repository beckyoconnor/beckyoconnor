{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4022bce",
   "metadata": {},
   "source": [
    "# Data / Feature Engineering\n",
    "\n",
    "In this notebook, we acheive the following feature engineering efforts:\n",
    "    - use image processing library to parse the image into matrices\n",
    "    - we reshape the matrice \n",
    "    - store the matrice into table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f152540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Initialization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURRENT_USER()</th>\n",
       "      <th>CURRENT_ROLE()</th>\n",
       "      <th>CURRENT_DATABASE()</th>\n",
       "      <th>CURRENT_SCHEMA()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BECKY</td>\n",
       "      <td>PUBLIC</td>\n",
       "      <td>INDSOL_DICOM_DB</td>\n",
       "      <td>PUBLIC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CURRENT_USER() CURRENT_ROLE() CURRENT_DATABASE() CURRENT_SCHEMA()\n",
       "0          BECKY         PUBLIC    INDSOL_DICOM_DB           PUBLIC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Image , Markdown\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "import os ,configparser ,json ,logging\n",
    "\n",
    "# Import the commonly defined utility scripts using\n",
    "# dynamic path include\n",
    "import sys\n",
    "sys.path.append('../python/lutils')\n",
    "import sflk_base as L\n",
    "\n",
    "display(Markdown(\"### Initialization\"))\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.ERROR)\n",
    "\n",
    "# Source various helper functions\n",
    "%run ./scripts/notebook_helpers.py\n",
    "\n",
    "# Define the project home directory, this is used for locating the config.ini file\n",
    "PROJECT_HOME_DIR = '../../'\n",
    "config = L.get_config('../../')\n",
    "\n",
    "sp_session = L.connect_to_snowflake(PROJECT_HOME_DIR)\n",
    "\n",
    "\n",
    "if(sp_session == None):\n",
    "    raise Exception(f'Unable to connect to snowflake. Validate connection information ')\n",
    "\n",
    "sp_session.use_role(f'''{config['APP_DB']['role']}''')\n",
    "sp_session.use_schema(f'''{config['APP_DB']['database']}.{config['APP_DB']['schema']}''')\n",
    "sp_session.use_warehouse(f'''{config['APP_DB']['snow_opt_wh']}''')\n",
    "\n",
    "df = sp_session.sql('select current_user() ,current_role() ,current_database() ,current_schema();').to_pandas()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c045d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# converts the image to array\n",
    "def convert_image_to_nparray(p_image_fl_path ,p_img_size ,p_class_label):\n",
    "    ex = ''\n",
    "    status = False\n",
    "    resized_arr = []\n",
    "    try:\n",
    "        img_arr = cv2.imread(p_image_fl_path, cv2.IMREAD_GRAYSCALE)\n",
    "        resized_arr = cv2.resize(img_arr, (p_img_size, p_img_size)) # Reshaping images to preferred size\n",
    "        status = True\n",
    "    except Exception as e:\n",
    "        ex = str(e)\n",
    "    return (status ,ex ,resized_arr)\n",
    "\n",
    "# iterate the data directory and for each image; we convert to matrice\n",
    "# and then reshape the matrices\n",
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "def images_to_pddf(p_data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(p_data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            img_flpath = os.path.join(path, img)\n",
    "            status ,ex ,image_arr = convert_image_to_nparray(img_flpath ,img_size ,label)\n",
    "            \n",
    "            arr_shape = np.shape(image_arr)\n",
    "\n",
    "            normalized_arr = np.array(image_arr) / 255\n",
    "            \n",
    "            resized_feature = normalized_arr.reshape(-1, img_size, img_size, 1)\n",
    "            data.append( (img_flpath ,label ,class_num ,status ,ex \n",
    "                ,image_arr.flatten() ,arr_shape[0] ,arr_shape[1] \n",
    "                ,normalized_arr.flatten() \n",
    "                ,resized_feature.flatten()) )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b868739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_pddf(p_data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(p_data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            img_flpath = os.path.join(path, img)\n",
    "            status ,ex ,image_arr = convert_image_to_nparray(img_flpath ,img_size ,label)\n",
    "            \n",
    "            arr_shape = np.shape(image_arr)\n",
    "\n",
    "            normalized_arr = np.array(image_arr) / 255\n",
    "            \n",
    "            resized_feature = normalized_arr.reshape(-1, img_size, img_size, 1)\n",
    "            data.append( (img_flpath ,label ,class_num ,status ,ex\n",
    "                ,arr_shape[0] ,arr_shape[1] \n",
    "                ,image_arr.flatten()\n",
    "                ,normalized_arr.flatten() \n",
    "                ,resized_feature.flatten()) )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f6fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "list_1 = images_to_pddf('../../data/train')\n",
    "list_2 = images_to_pddf('../../data/test')\n",
    "list_3 = images_to_pddf('../../data/val')\n",
    "\n",
    "\n",
    "\n",
    "images_parsed_list = list_1 + list_2 + list_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546b747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parsed images are then stored in a table\n",
    "\n",
    "images_parsed_pddf = pd.DataFrame(images_parsed_list\n",
    "    , columns =['image_filepath', 'class_label','class_num','status','parsing_exception'\n",
    "        ,'image_array' ,'image_array_shape_0' ,'image_array_shape_1' \n",
    "        ,'normalized_image_array' ,'resized_feature'])\n",
    "\n",
    "images_parsed_pddf.columns = map(lambda x: str(x).upper(), images_parsed_pddf.columns)\n",
    "\n",
    "tbl_schema = T.StructType([\n",
    "    T.StructField('IMAGE_FILEPATH', T.StringType())\n",
    "    ,T.StructField('CLASS_LABEL', T.StringType())\n",
    "    ,T.StructField('CLASS_NUM', T.IntegerType())\n",
    "    ,T.StructField('STATUS', T.BooleanType())\n",
    "    ,T.StructField('PARSING_EXCEPTION', T.StringType())\n",
    "    ,T.StructField('IMAGE_ARRAY', T.VariantType())\n",
    "    ,T.StructField('IMAGE_ARRAY_SHAPE_0', T.IntegerType())\n",
    "    ,T.StructField('IMAGE_ARRAY_SHAPE_1', T.IntegerType())\n",
    "    ,T.StructField('NORMALIZED_IMAGE_ARRAY', T.VariantType())\n",
    "    ,T.StructField('RESIZED_FEATURE', T.VariantType())\n",
    "])\n",
    "\n",
    "img_table = f'''{config['APP_DB']['database']}.public.images_parsed'''\n",
    "\n",
    "df = sp_session.create_dataframe(images_parsed_pddf\n",
    "    , schema=tbl_schema)\n",
    "df.write.save_as_table(img_table, mode=\"overwrite\" ,table_type='transient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a1cc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGE_FILEPATH</th>\n",
       "      <th>CLASS_LABEL</th>\n",
       "      <th>CLASS_NUM</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>PARSING_EXCEPTION</th>\n",
       "      <th>IMAGE_ARRAY</th>\n",
       "      <th>IMAGE_ARRAY_SHAPE_0</th>\n",
       "      <th>IMAGE_ARRAY_SHAPE_1</th>\n",
       "      <th>NORMALIZED_IMAGE_ARRAY</th>\n",
       "      <th>RESIZED_FEATURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/val/PNEUMONIA/person1609_virus_2791...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>[\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n  1,\\n  2,\\n ...</td>\n",
       "      <td>[\\n  0.000000000000000e+00,\\n  0.0000000000000...</td>\n",
       "      <td>[\\n  0.000000000000000e+00,\\n  0.0000000000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/val/PNEUMONIA/person301_bacteria_14...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>[\\n  26,\\n  25,\\n  24,\\n  24,\\n  27,\\n  26,\\n ...</td>\n",
       "      <td>[\\n  1.019607843137255e-01,\\n  9.8039215686274...</td>\n",
       "      <td>[\\n  1.019607843137255e-01,\\n  9.8039215686274...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/train/PNEUMONIA/person1481_bacteria...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>[\\n  3,\\n  3,\\n  2,\\n  1,\\n  1,\\n  0,\\n  0,\\n ...</td>\n",
       "      <td>[\\n  1.176470588235294e-02,\\n  1.1764705882352...</td>\n",
       "      <td>[\\n  1.176470588235294e-02,\\n  1.1764705882352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/train/PNEUMONIA/person1562_bacteria...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>[\\n  61,\\n  59,\\n  78,\\n  66,\\n  86,\\n  177,\\n...</td>\n",
       "      <td>[\\n  2.392156862745098e-01,\\n  2.3137254901960...</td>\n",
       "      <td>[\\n  2.392156862745098e-01,\\n  2.3137254901960...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/train/PNEUMONIA/person490_bacteria_...</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>[\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n ...</td>\n",
       "      <td>[\\n  0.000000000000000e+00,\\n  0.0000000000000...</td>\n",
       "      <td>[\\n  0.000000000000000e+00,\\n  0.0000000000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      IMAGE_FILEPATH CLASS_LABEL  CLASS_NUM  \\\n",
       "0  ../../data/val/PNEUMONIA/person1609_virus_2791...   PNEUMONIA          0   \n",
       "1  ../../data/val/PNEUMONIA/person301_bacteria_14...   PNEUMONIA          0   \n",
       "2  ../../data/train/PNEUMONIA/person1481_bacteria...   PNEUMONIA          0   \n",
       "3  ../../data/train/PNEUMONIA/person1562_bacteria...   PNEUMONIA          0   \n",
       "4  ../../data/train/PNEUMONIA/person490_bacteria_...   PNEUMONIA          0   \n",
       "\n",
       "   STATUS PARSING_EXCEPTION  IMAGE_ARRAY  IMAGE_ARRAY_SHAPE_0  \\\n",
       "0    True                            150                  150   \n",
       "1    True                            150                  150   \n",
       "2    True                            150                  150   \n",
       "3    True                            150                  150   \n",
       "4    True                            150                  150   \n",
       "\n",
       "                                 IMAGE_ARRAY_SHAPE_1  \\\n",
       "0  [\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n  1,\\n  2,\\n ...   \n",
       "1  [\\n  26,\\n  25,\\n  24,\\n  24,\\n  27,\\n  26,\\n ...   \n",
       "2  [\\n  3,\\n  3,\\n  2,\\n  1,\\n  1,\\n  0,\\n  0,\\n ...   \n",
       "3  [\\n  61,\\n  59,\\n  78,\\n  66,\\n  86,\\n  177,\\n...   \n",
       "4  [\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n  0,\\n ...   \n",
       "\n",
       "                              NORMALIZED_IMAGE_ARRAY  \\\n",
       "0  [\\n  0.000000000000000e+00,\\n  0.0000000000000...   \n",
       "1  [\\n  1.019607843137255e-01,\\n  9.8039215686274...   \n",
       "2  [\\n  1.176470588235294e-02,\\n  1.1764705882352...   \n",
       "3  [\\n  2.392156862745098e-01,\\n  2.3137254901960...   \n",
       "4  [\\n  0.000000000000000e+00,\\n  0.0000000000000...   \n",
       "\n",
       "                                     RESIZED_FEATURE  \n",
       "0  [\\n  0.000000000000000e+00,\\n  0.0000000000000...  \n",
       "1  [\\n  1.019607843137255e-01,\\n  9.8039215686274...  \n",
       "2  [\\n  1.176470588235294e-02,\\n  1.1764705882352...  \n",
       "3  [\\n  2.392156862745098e-01,\\n  2.3137254901960...  \n",
       "4  [\\n  0.000000000000000e+00,\\n  0.0000000000000...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_table = f'''{config['APP_DB']['database']}.public.images_parsed'''\n",
    "\n",
    "df = sp_session.table(img_table).limit(5).to_pandas()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ffbf6",
   "metadata": {},
   "source": [
    "--- \n",
    "### Closeout\n",
    "\n",
    "    With that we are finished this section of the demo setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "192cf880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!!!\n"
     ]
    }
   ],
   "source": [
    "sp_session.close()\n",
    "print('Finished!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pysnowpark002')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "315dab235d255f2b1c7437423d39654c13de0e7fada135e10cd0414d917adbdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
